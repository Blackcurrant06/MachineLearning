{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Load File"
      ],
      "metadata": {
        "id": "1f39CBsHhrcb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rrBBCgx4hhB-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('Automobile.csv')\n",
        "print(f\"Shape of the DataFrame: {df.shape}\")\n",
        "display(df.head())\n",
        "# df.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cleaning"
      ],
      "metadata": {
        "id": "ErpxWjnajEUT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for col in ['normalized-losses', 'bore', 'stroke', 'horsepower', 'peak-rpm', 'price']:\n",
        "    df[col] = df[col].fillna(df[col].median())\n",
        "df['num-of-doors'].fillna(df['num-of-doors'].mode()[0], inplace=True)\n",
        "\n",
        "for col in ['normalized-losses', 'bore', 'stroke', 'horsepower', 'peak-rpm', 'price']:\n",
        "    df[col] = pd.to_numeric(df[col], errors='coerce')"
      ],
      "metadata": {
        "id": "OHkx5p-ijLPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Splitting"
      ],
      "metadata": {
        "id": "1q856nRAy3Iy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Feature Selection (justify choices in comments)\n",
        "features = ['make', 'fuel-type', 'aspiration', 'num-of-doors', 'body-style', 'drive-wheels', 'engine-location', 'wheel-base', 'length', 'width', 'height', 'curb-weight', 'engine-size', 'num-of-cylinders', 'horsepower', 'peak-rpm', 'city-mpg', 'highway-mpg', 'price', 'normalized-losses']\n",
        "# Selected features based on intuition and previous exploration.  Features like 'make', 'fuel-type', etc., are likely to be influential in determining insurance risk.\n",
        "\n",
        "X = df[features]\n",
        "y = df['symboling']\n",
        "\n",
        "# One-Hot Encoding\n",
        "categorical_features = ['make', 'fuel-type', 'aspiration', 'num-of-doors', 'body-style', 'drive-wheels', 'engine-location', 'num-of-cylinders']\n",
        "numerical_features = ['wheel-base', 'length', 'width', 'height', 'curb-weight', 'engine-size', 'horsepower', 'peak-rpm', 'city-mpg', 'highway-mpg', 'price', 'normalized-losses']\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numerical_features),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
        "    ])\n",
        "\n",
        "X_processed = preprocessor.fit_transform(X)\n",
        "\n",
        "# Create a new dataframe with the processed features\n",
        "X_processed_df = pd.DataFrame(X_processed)\n",
        "\n",
        "display(X_processed_df.head())\n",
        "###\n",
        "\n",
        "\n",
        "# Assuming 'y' is already defined as the target variable (symboling)\n",
        "y = df['symboling']\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_processed_df, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"y_test shape: {y_test.shape}\")"
      ],
      "metadata": {
        "id": "hCs0yDhKzpgX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "zyVrEzS3z-If"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Instantiate a LinearRegression object\n",
        "linear_regression_model = LinearRegression()\n",
        "\n",
        "# Train the model using the training data\n",
        "linear_regression_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "rQS3Sf-a0MmB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evalauasi"
      ],
      "metadata": {
        "id": "OYRZC5It00xn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = linear_regression_model.predict(X_test)\n",
        "\n",
        "# Calculate RMSE\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "\n",
        "# Calculate MSE\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "# Calculate R-squared\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "# Print the evaluation metrics along with formulas and explanations\n",
        "print(\"Evaluation Metrics:\")\n",
        "\n",
        "print(\"\\n1. Root Mean Squared Error (RMSE)\")\n",
        "print(\"Formula: RMSE = sqrt(MSE) = sqrt(1/n * Σ(yi - ŷi)^2)\")\n",
        "print(\"Meaning: RMSE measures the average difference between the predicted and actual values in the same unit as the target variable.  Lower RMSE indicates better model performance.  A good score is close to 0, indicating that the model's predictions are very accurate.  A bad score is a high value, meaning the model's predictions are significantly off.\")\n",
        "print(f\"RMSE: {rmse}\")\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(y_test, y_pred)\n",
        "plt.xlabel(\"Actual Symboling\")\n",
        "plt.ylabel(\"Predicted Symboling\")\n",
        "plt.title(\"Actual vs Predicted Symboling\")\n",
        "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red') # Add a diagonal line for reference\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n2. Mean Squared Error (MSE)\")\n",
        "print(\"Formula: MSE = 1/n * Σ(yi - ŷi)^2\")\n",
        "print(\"Meaning: MSE calculates the average squared difference between predicted and actual values.  It penalizes larger errors more heavily than smaller errors.  Similar to RMSE, a lower MSE signifies better performance.  A good score is close to 0, and a bad score is a large value.\")\n",
        "print(f\"MSE: {mse}\")\n",
        "\n",
        "residuals = y_test - y_pred\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(y_pred, residuals)\n",
        "plt.xlabel(\"Predicted Symboling\")\n",
        "plt.ylabel(\"Residuals\")\n",
        "plt.title(\"Residual Plot\")\n",
        "plt.axhline(y=0, color='red', linestyle='--')  # Add a horizontal line at y=0\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n3. R-squared (R2)\")\n",
        "print(\"Formula: R^2 = 1 - (SSres / SStot) = 1 - [Σ(yi - ŷi)^2 / Σ(yi - ȳ)^2]\")\n",
        "print(\"Meaning: R-squared represents the proportion of variance in the target variable explained by the model.  It ranges from 0 to 1, where 1 indicates that the model perfectly fits the data.  A good score is close to 1, indicating that a high proportion of the variance is explained. A bad score is close to 0, suggesting the model doesn't explain much of the variance.\")\n",
        "print(f\"R-squared: {r2}\")\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.hist(residuals, bins=15)\n",
        "plt.xlabel(\"Residuals\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.title(\"Distribution of Residuals\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "sBJwvLWU02dx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}